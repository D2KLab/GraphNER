{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "vocabulary = pickle.load(open('edges/vocabulary.pickle', 'rb'))\n",
    "word2id = {w:i for i,w in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
    "\n",
    "import gem\n",
    "from gem.utils import graph_util, plot_util\n",
    "from gem.evaluation import visualize_embedding as viz\n",
    "from gem.evaluation import evaluate_graph_reconstruction as gr\n",
    "from time import time\n",
    "\n",
    "from gem.embedding.gf       import GraphFactorization\n",
    "from gem.embedding.hope     import HOPE\n",
    "from gem.embedding.lap      import LaplacianEigenmaps\n",
    "from gem.embedding.lle      import LocallyLinearEmbedding\n",
    "from gem.embedding.node2vec import node2vec\n",
    "from gem.embedding.sdne     import SDNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "edges_file = 'edges/all_edges.edgelist'\n",
    "G = graph_util.loadGraphFromEdgeListTxt(edges_file, directed=True)\n",
    "G = G.to_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.edges), len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "output_embeddings = {}\n",
    "embeddings_dim = 300\n",
    "\n",
    "# models.append(GraphFactorization(d=2, max_iter=100000, eta=1*10**-4, regu=1.0, data_set='karate'))\n",
    "models.append(HOPE(d=embeddings_dim, beta=0.01))\n",
    "# Training time: 99.340407\n",
    "\n",
    "\n",
    "# LE takes embedding dimension (d) as input\n",
    "models.append(LaplacianEigenmaps(d=embeddings_dim))\n",
    "# Training time: 10.422501\n",
    "\n",
    "\n",
    "# LLE takes embedding dimension (d) as input\n",
    "models.append(LocallyLinearEmbedding(d=embeddings_dim))\n",
    "# Training time: 167.512155\n",
    "\n",
    "\n",
    "# node2vec takes embedding dimension (d),  maximum iterations (max_iter), random walk length (walk_len), number of random walks (num_walks), context size (con_size), return weight (ret_p), inout weight (inout_p) as inputs\n",
    "models.append(node2vec(d=embeddings_dim, max_iter=5, walk_len=20, num_walks=10, con_size=2, ret_p=1, inout_p=1))\n",
    "\n",
    "# SDNE takes embedding dimension (d), seen edge reconstruction weight (beta), first order proximity weight (alpha), lasso regularization coefficient (nu1), ridge regreesion coefficient (nu2), number of hidden layers (K), size of each layer (n_units), number of iterations (n_ite), learning rate (xeta), size of batch (n_batch), location of modelfile and weightfile save (modelfile and weightfile) as inputs\n",
    "models.append(SDNE(d=embeddings_dim, beta=5, alpha=1e-5, nu1=1e-6, nu2=1e-6, K=3, n_units=[50, 15,], n_iter=50, xeta=0.01, n_batch=500,))\n",
    "              modelfile=['enc_model.json', 'dec_model.json'],\n",
    "              weightfile=['enc_weights.hdf5', 'dec_weights.hdf5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding in models:\n",
    "    print ('Num nodes: %d, num edges: %d' % (G.number_of_nodes(), G.number_of_edges()))\n",
    "    t1 = time()\n",
    "    # Learn embedding - accepts a networkx graph or file with edge list\n",
    "    Y, t = embedding.learn_embedding(graph=G, edge_f=None, is_weighted=True, no_python=True)\n",
    "    print (embedding._method_name+':\\n\\tTraining time: %f' % (time() - t1))\n",
    "    # Evaluate on graph reconstruction\n",
    "    # MAP, prec_curv, err, err_baseline = gr.evaluateStaticGraphReconstruction(G, embedding, Y, None)\n",
    "    output_embeddings[embedding._method_name] = (embedding, Y, t)\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # print((\"\\tMAP: {} \\t precision curve: {}\\n\\n\\n\\n\"+'-'*100).format(MAP,prec_curv[:5]))\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # Visualize\n",
    "    # viz.plot_embedding2D(embedding.get_embedding(), di_graph=G, node_colors=None)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding_name in output_embeddings:\n",
    "    # embedding, Y, t = output_embeddings[embedding_name]\n",
    "    # MAP, prec_curv, err, err_baseline = gr.evaluateStaticGraphReconstruction(G, embedding, Y, None)\n",
    "    # print((\"\\tMAP: {} \\t precision curve: {}\\n\\n\\n\\n\"+'-'*100).format(MAP,prec_curv[:5]))\n",
    "    print(embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding_name in output_embeddings:\n",
    "    embedding, Y, t = output_embeddings[embedding_name]\n",
    "    embeddings_dict = {w: Y[i] for i, w in enumerate(vocabulary)}\n",
    "    pickle.dump(embeddings_dict, open('edges/'+embedding_name+'_all_embeddings.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.get_embedding(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
