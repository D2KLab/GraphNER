{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "[X]  Adding other info such as \"Capitalized\" and \"contains punctuation\"\n",
    "\n",
    "[_]  Two-stage encoding (first the node then the context)\n",
    "\n",
    "[_]  Use Graph Embeddings instead of one hot embeddings\n",
    "\n",
    "[_]  Accounting for OOV (randomly injecting some \"UNK\" token/only when the token doesn't appear in Conceptnet/Gazetteer)\n",
    "\n",
    "[_]  Use Word Pieces\n",
    "\n",
    "[_]  Autoencoder / Cloze pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorials\n",
    "https://huggingface.co/docs/datasets/loading_datasets.html\n",
    "https://www.learnopencv.com/tensorboard-with-pytorch-lightning/\n",
    "https://discuss.pytorch.org/t/pytorch-coding-conventions/42548\n",
    "https://huggingface.co/transformers/examples.html\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/new-project.html\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/rapid_prototyping_templates.html\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/style_guide.html\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/performance.html\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/loggers.html\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/metrics.html\n",
    "https://pytorch-lightning.readthedocs.io/en/stable/weights_loading.html\n",
    "https://pytorch-lightning.readthedocs.io/en/0.4.9/Trainer/Checkpointing/\n",
    "https://pytorch-lightning.readthedocs.io/en/stable/metrics.html#stat-scores-multiple-classes-func\n",
    "https://pytorch-lightning-bolts.readthedocs.io/en/latest/classic_ml.html#logistic-regression\n",
    "https://pytorch-lightning.readthedocs.io/en/latest/trainer.html\n",
    "https://github.com/PyTorchLightning/deep-learning-project-template\n",
    "https://github.com/PyTorchLightning/pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip uninstall torchvision\n",
    "# ! pip -q install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2, 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy, f1_score, stat_scores_multiple_classes\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.5 s, sys: 743 ms, total: 50.2 s\n",
      "Wall time: 50.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, Y_train = zip(*pickle.load(open('data/conll2003_sparse_train.pickle', 'rb')))\n",
    "X_dev,   Y_dev   = zip(*pickle.load(open('data/conll2003_sparse_test.pickle', 'rb')))\n",
    "X_test,  Y_test  = zip(*pickle.load(open('data/conll2003_sparse_test.pickle', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172046"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X_train = [x.to_dense()  for x in tqdm(X_train)]\n",
    "# X_dev = [x.to_dense()  for x in tqdm(X_dev)]\n",
    "# X_test = [x.to_dense()  for x in tqdm(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 62981\n",
    "labels = ['PER', 'ORG', 'LOC', 'MISC', 'O']\n",
    "labels_to_id = {l:i for i, l in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39107"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, labels):\n",
    "        \"\"\"\n",
    "            X = Input matrix, shape: [N_samples, dim_sample]\n",
    "            Y = Output list, shape: [N_samples], contains labels strings\n",
    "            labels = textual labels for the classes\n",
    "        \"\"\"\n",
    "        assert(len(X) == len(Y))\n",
    "        assert(all([label in labels for label in Y]))\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_len = len(X)\n",
    "        self.Y_len = len(labels)\n",
    "        self.labels = sorted(labels)\n",
    "        self.y2index = {l: i for i, l in enumerate(labels)}\n",
    "        self.y2onehot = {l: np.eye(self.Y_len)[i] for i, l in enumerate(labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index].to_dense().clone().detach() #.to('cuda') # [:voc_size]\n",
    "        y = self.y2index[self.Y[index]]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_set = Dataset(X_train, Y_train, labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "dev_set = Dataset(X_dev, Y_dev, labels)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_set, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "test_set = Dataset(X_test, Y_test, labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 62981])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 62981])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for local_features, local_labels in train_loader:\n",
    "    print(local_features.shape)\n",
    "    print(local_labels.shape)\n",
    "    break\n",
    "\n",
    "for local_features, local_labels in dev_loader:\n",
    "    print(local_features.shape)\n",
    "    print(local_labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ORG': 9941, 'O': 138124, 'MISC': 4570, 'PER': 11124, 'LOC': 8287})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_training_labels = []\n",
    "# for local_features, local_labels in train_loader:\n",
    "#     all_training_labels.extend([x for x in local_labels.numpy()])\n",
    "# training_counter = Counter(all_training_labels)\n",
    "training_counter = Counter(Y_train)\n",
    "training_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4108, 0.4597, 0.5515, 1.0000, 0.0331])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights = np.power(labels_df.iloc[train_IDs][action].value_counts().values, 1)\n",
    "weights = torch.Tensor([min(training_counter.values())/training_counter[cls] for cls in labels]) #.to('cuda')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, input_dim=input_size, hidden_dim=1024, output_dim=5, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.l1 = torch.nn.Linear(self.hparams.input_dim, self.hparams.hidden_dim)\n",
    "        self.l2 = torch.nn.Linear(self.hparams.hidden_dim, output_dim)\n",
    "        self.l3 = torch.nn.Linear(self.hparams.hidden_dim, self.hparams.hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.l1(x))\n",
    "        # x = torch.relu(self.l3(x))\n",
    "        x = torch.relu(self.l2(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y, weight=weights)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        f1 = f1_score(preds, y)\n",
    "        self.log('valid_loss', loss)\n",
    "        self.log('valid_acc', f1)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        f1 = accuracy(preds, y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', f1)\n",
    "\n",
    "    def evaluate(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        \n",
    "        return preds.to('cpu')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | l1   | Linear | 64 M  \n",
      "1 | l2   | Linear | 5 K   \n",
      "2 | l3   | Linear | 1 M   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f993f40b4341a4853f24c771dee3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea2ff32703c412d8e135947e09741b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928c66e0160f4e5e84961d3f7acb728c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93ca6fd4689448bbebc2ebe1e8bf488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea5d0a2821c4cebb6a3a349922ea23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09b12d3e35d4711ba97ed3d40019c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.8491),\n",
      " 'test_loss': tensor(1.5345),\n",
      " 'valid_acc': tensor(nan),\n",
      " 'valid_loss': tensor(1.5345)}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "CPU times: user 19h 8min 27s, sys: 2h 17min 35s, total: 21h 26min 3s\n",
      "Wall time: 1h 34min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'valid_loss': 1.5344531536102295,\n",
       "  'valid_acc': nan,\n",
       "  'test_loss': 1.5344531536102295,\n",
       "  'test_acc': 0.8490551710128784}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "model = MLP(learning_rate=1e-3)\n",
    "\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "trainer = pl.Trainer(max_epochs=3)#, gpus='0')\n",
    "trainer.fit(model, train_loader, dev_loader)\n",
    "\n",
    "# ------------\n",
    "# testing\n",
    "# ------------\n",
    "trainer.test(test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e859a463f21453194913bff249546df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "39107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 2413.,     0.,     0.,     0., 30791.]),\n",
       " tensor([ 482.,    0.,    0.,    0., 5421.]),\n",
       " tensor([35852., 36616., 37182., 38195.,  2680.]),\n",
       " tensor([ 360., 2491., 1925.,  912.,  215.]),\n",
       " tensor([ 2773.,  2491.,  1925.,   912., 31006.]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gt = []\n",
    "for local_features, local_labels in tqdm(test_loader, total=len(test_loader)):\n",
    "    preds.extend(torch.argmax(model(local_features), dim=1))\n",
    "    gt.extend(local_labels)\n",
    "\n",
    "print(len(preds))\n",
    "results = stat_scores_multiple_classes(torch.tensor(preds), torch.tensor(gt))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 2413.,     0.,     0.,     0., 30791.]),\n",
       " tensor([ 482.,    0.,    0.,    0., 5421.]),\n",
       " tensor([35852., 36616., 37182., 38195.,  2680.]),\n",
       " tensor([ 360., 2491., 1925.,  912.,  215.]),\n",
       " tensor([ 2773.,  2491.,  1925.,   912., 31006.]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(preds))\n",
    "results = stat_scores_multiple_classes(torch.tensor(preds), torch.tensor(gt))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER \t 2773 \t 2895 \t 104.4%\n",
      "ORG \t 2491 \t 0 \t 0.0%\n",
      "LOC \t 1925 \t 0 \t 0.0%\n",
      "MISC \t 912 \t 0 \t 0.0%\n",
      "O \t 31006 \t 36212 \t 116.78999999999999%\n"
     ]
    }
   ],
   "source": [
    "gt_count = Counter(torch.tensor(gt).numpy())\n",
    "pr_count = Counter(torch.tensor(preds).numpy())\n",
    "\n",
    "for i, l in enumerate(labels):\n",
    "    print(l, '\\t', gt_count[i], '\\t', pr_count[i],  '\\t', str(round(pr_count[i] / gt_count[i], 4)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      2773\n",
      "           1       0.00      0.00      0.00      2491\n",
      "           2       0.00      0.00      0.00      1925\n",
      "           3       0.00      0.00      0.00       912\n",
      "           4       0.85      0.99      0.92     31006\n",
      "\n",
      "    accuracy                           0.85     39107\n",
      "   macro avg       0.34      0.37      0.35     39107\n",
      "weighted avg       0.73      0.85      0.79     39107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(torch.tensor(gt).numpy(), torch.tensor(preds).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=1e-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.59      0.73      2773\n",
      "           1       0.80      0.59      0.68      2491\n",
      "           2       0.00      0.00      0.00      1925\n",
      "           3       0.00      0.00      0.00       912\n",
      "           4       0.87      1.00      0.93     31006\n",
      "\n",
      "    accuracy                           0.87     39107\n",
      "   macro avg       0.52      0.44      0.47     39107\n",
      "weighted avg       0.81      0.87      0.83     39107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"lr=1e-2, n_epochs=?, ws=3, \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.59      0.73      2773\n",
    "           1       0.80      0.59      0.68      2491\n",
    "           2       0.00      0.00      0.00      1925\n",
    "           3       0.00      0.00      0.00       912\n",
    "           4       0.87      1.00      0.93     31006\n",
    "\n",
    "    accuracy                           0.87     39107\n",
    "   macro avg       0.52      0.44      0.47     39107\n",
    "weighted avg       0.81      0.87      0.83     39107\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=1e-2\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2773\n",
      "           1       0.00      0.00      0.00      2491\n",
      "           2       0.00      0.00      0.00      1925\n",
      "           3       0.00      0.00      0.00       912\n",
      "           4       0.79      1.00      0.88     31006\n",
      "\n",
      "    accuracy                           0.79     39107\n",
      "   macro avg       0.16      0.20      0.18     39107\n",
      "weighted avg       0.63      0.79      0.70     39107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"lr=1e-1, n_epochs=5, ws=3, \n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00      2773\n",
    "           1       0.00      0.00      0.00      2491\n",
    "           2       0.00      0.00      0.00      1925\n",
    "           3       0.00      0.00      0.00       912\n",
    "           4       0.79      1.00      0.88     31006\n",
    "\n",
    "    accuracy                           0.79     39107\n",
    "   macro avg       0.16      0.20      0.18     39107\n",
    "weighted avg       0.63      0.79      0.70     39107\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epochs=30, hidden_size=512, 1e-3\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.39      0.56      2773\n",
      "           1       0.00      0.00      0.00      2491\n",
      "           2       0.00      0.00      0.00      1925\n",
      "           3       0.00      0.00      0.00       912\n",
      "           4       0.82      1.00      0.90     31006\n",
      "\n",
      "    accuracy                           0.82     39107\n",
      "   macro avg       0.36      0.28      0.29     39107\n",
      "weighted avg       0.72      0.82      0.75     39107\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"n_epochs=30, hidden_size=512x1, 1e-3\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.39      0.56      2773\n",
    "           1       0.00      0.00      0.00      2491\n",
    "           2       0.00      0.00      0.00      1925\n",
    "           3       0.00      0.00      0.00       912\n",
    "           4       0.82      1.00      0.90     31006\n",
    "\n",
    "    accuracy                           0.82     39107\n",
    "   macro avg       0.36      0.28      0.29     39107\n",
    "weighted avg       0.72      0.82      0.75     39107\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epochs=3, hidden_size=128x2, \n",
      "PER \t 2773 \t 0 \t 0.0%\n",
      "ORG \t 2491 \t 0 \t 0.0%\n",
      "LOC \t 1925 \t 0 \t 0.0%\n",
      "MISC \t 912 \t 0 \t 0.0%\n",
      "O \t 31006 \t 39107 \t 126.13000000000001%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"n_epochs=3, hidden_size=128x2, \n",
    "PER \t 2773 \t 0 \t 0.0%\n",
    "ORG \t 2491 \t 0 \t 0.0%\n",
    "LOC \t 1925 \t 0 \t 0.0%\n",
    "MISC \t 912 \t 0 \t 0.0%\n",
    "O \t 31006 \t 39107 \t 126.13000000000001%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=1e-4\n",
      "weights=on\n",
      "epochs=2\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2773\n",
      "           1       0.37      0.81      0.51      2491\n",
      "           2       0.70      0.84      0.76      1925\n",
      "           3       0.47      0.78      0.59       912\n",
      "           4       0.96      0.93      0.95     31006\n",
      "\n",
      "    accuracy                           0.85     39107\n",
      "   macro avg       0.50      0.67      0.56     39107\n",
      "weighted avg       0.83      0.85      0.83     39107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"lr=1e-4\n",
    "weights=on\n",
    "epochs=2\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00      2773\n",
    "           1       0.37      0.81      0.51      2491\n",
    "           2       0.70      0.84      0.76      1925\n",
    "           3       0.47      0.78      0.59       912\n",
    "           4       0.96      0.93      0.95     31006\n",
    "\n",
    "    accuracy                           0.85     39107\n",
    "   macro avg       0.50      0.67      0.56     39107\n",
    "weighted avg       0.83      0.85      0.83     39107\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "lr=1e-3\n",
    "max_epochs=3\n",
    "hidden=512\n",
    "weights=on\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.79      0.85      2773\n",
    "           1       0.00      0.00      0.00      2491\n",
    "           2       0.78      0.84      0.81      1925\n",
    "           3       0.59      0.74      0.65       912\n",
    "           4       0.91      0.99      0.95     31006\n",
    "\n",
    "    accuracy                           0.90     39107\n",
    "   macro avg       0.64      0.67      0.65     39107\n",
    "weighted avg       0.84      0.90      0.87     39107\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
