{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "[X]  Adding other info such as \"Capitalized\" and \"contains punctuation\"\n",
    "\n",
    "[_]  Two-stage encoding (first the node then the context)\n",
    "\n",
    "[_]  Use Graph Embeddings instead of one hot embeddings\n",
    "\n",
    "[_]  Data Aug: add edges from embedding-similar words who share the same class\n",
    "\n",
    "[_]  Accounting for OOV (randomly injecting some \"UNK\" token/only when the token doesn't appear in Conceptnet/Gazetteer)\n",
    "\n",
    "[_]  Use Word Pieces\n",
    "\n",
    "[_]  Autoencoder / Cloze pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  7 02:50:17 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.04    Driver Version: 455.23.04    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   24C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   30C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           On   | 00000000:09:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    57W / 149W |    331MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   51C    P8    32W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A    311141      C   ...l-transformers/bin/python      326MiB |\n",
      "|    3   N/A  N/A    311141      C   ...l-transformers/bin/python        0MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, Y_train = zip(*pickle.load(open('data/conll2003_sparse_train.pickle', 'rb')))\n",
    "X_dev,   Y_dev   = zip(*pickle.load(open('data/conll2003_sparse_dev.pickle',   'rb')))\n",
    "X_test,  Y_test  = zip(*pickle.load(open('data/conll2003_sparse_test.pickle',  'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172046, 43525, 39107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 62981\n",
    "labels = ['PER', 'ORG', 'LOC', 'MISC', 'O']\n",
    "labels_to_id = {l:i for i, l in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "62981 - 62937 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06465712658242563, 0.057781058554107624, 0.048167350592283456, 0.026562663473722145, 0.8028318007974612]\n",
      "[0.4108234448040273, 0.459712302585253, 0.5514661518040304, 1.0, 0.033086212388867976]\n",
      "[0.6409551035790473, 0.6780208717917561, 0.7426076701758677, 1.0, 0.1818961582575838]\n"
     ]
    }
   ],
   "source": [
    "label_counter   = Counter(Y_train)\n",
    "labels_freqs    = [label_counter[label] / sum(label_counter.values()) for label in labels]\n",
    "labels_weights  = [min(label_counter.values()) / label_counter[label] for label in labels]\n",
    "labels_weights2 = [np.sqrt(min(label_counter.values())) / np.sqrt(label_counter[label]) for label in labels]\n",
    "print(labels_freqs)\n",
    "print(labels_weights)\n",
    "print(labels_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Device:', device)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y, labels):\n",
    "        'Initialization'\n",
    "        self.X = X\n",
    "        self.y2index = {l: i for i, l in enumerate(labels)}\n",
    "        self.Y = Y\n",
    "        self.labels = labels\n",
    "        assert(len(X) == len(Y))\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        x = self.X[index].to_dense().clone().detach() #.to('cuda') # [:voc_size]\n",
    "        y = self.y2index[self.Y[index]]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "num_workers = 4\n",
    "\n",
    "\n",
    "sampling_probs = [labels_weights2[labels_to_id[l]] for l in Y_train]\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(sampling_probs, len(Y_train), replacement=True)\n",
    "train_set = Dataset(X_train, Y_train, labels)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True) # , sampler=sampler) #\n",
    "\n",
    "dev_set = Dataset(X_dev, Y_dev, labels)\n",
    "dev_loader = DataLoader(dev_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "test_set = Dataset(X_test, Y_test, labels)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5377\n",
      "torch.Size([32, 62981])\n",
      "torch.Size([32])\n",
      "tensor(8.)\n",
      "Class distribution in this batch: Counter({4: 28, 2: 2, 1: 1, 3: 1})\n",
      "time: 1.05s\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(len(train_loader))\n",
    "for batch_X, batch_Y in train_loader:\n",
    "    print(batch_X.shape)\n",
    "    print(batch_Y.shape)\n",
    "    print(sum(batch_X[0]))\n",
    "    print('Class distribution in this batch:', Counter(batch_Y.numpy()))\n",
    "    break\n",
    "print(f'time: {time.time() - t:.3}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model / Training / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=None,filename_suffix='reproducingbest')\n",
    "# writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(batch_X, batch_Y, model, optimizer, loss_fn):\n",
    "    Y_hat = model(batch_X)\n",
    "    loss = loss_fn(Y_hat, batch_Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=input_dim, hidden_dim=512, output_dim=5, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fch = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # extra layers layers\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        # self.batchnorm1 = nn.BatchNorm1d(hidden_dim)\n",
    "        # self.batchnorm2 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        #x = self.fch2(x)\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.relu(x)\n",
    "        logits = self.fc2(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = {'loss/train': {}, 'dev': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnet = FeedForwardNetwork().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6410, 0.6780, 0.7426, 1.0000, 0.1819], device='cuda:0')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_interval = int(len(train_loader) / 4)\n",
    "weights = torch.Tensor(labels_weights2).to('cuda')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_params = {'lr': 1e-5, \n",
    "                    'momentum': 0.9, \n",
    "                    'weight_decay': 5e-4,\n",
    "                   }\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.SGD(ffnet.parameters(), **optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7409481fea4882a2c6a3eb5ef25675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [0/172046 (0%)]\tLoss: 0.029863\n",
      "Train Epoch: 20 [43008/172046 (25%)]\tLoss: 0.075671\n",
      "Train Epoch: 20 [86016/172046 (50%)]\tLoss: 0.018723\n",
      "Train Epoch: 20 [129024/172046 (75%)]\tLoss: 0.052587\n",
      "Train Epoch: 20 [75264/172046 (100%)]\tLoss: 0.061429\n",
      "\n",
      "Average loss on epoch 20: 0.05545189463163582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb77ac92f2d422dbf43a9466ccbd501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9251    0.8875    0.9059      3270\n",
      "           1     0.8197    0.7521    0.7845      2231\n",
      "           2     0.8791    0.9279    0.9028      1983\n",
      "           3     0.7850    0.8757    0.8278      1134\n",
      "           4     0.9871    0.9893    0.9882     34907\n",
      "\n",
      "    accuracy                         0.9637     43525\n",
      "   macro avg     0.8792    0.8865    0.8819     43525\n",
      "weighted avg     0.9637    0.9637    0.9635     43525\n",
      "\n",
      "Epoch 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a043f646fa79453fa5d17780562b0f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [0/172046 (0%)]\tLoss: 0.051269\n",
      "Train Epoch: 21 [43008/172046 (25%)]\tLoss: 0.256115\n",
      "Train Epoch: 21 [86016/172046 (50%)]\tLoss: 0.064076\n",
      "Train Epoch: 21 [129024/172046 (75%)]\tLoss: 0.023900\n",
      "Train Epoch: 21 [75264/172046 (100%)]\tLoss: 0.023755\n",
      "\n",
      "Average loss on epoch 21: 0.05548100383044753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28ed10ba3a341e08bba0593db9ba640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9248    0.8874    0.9057      3269\n",
      "           1     0.8197    0.7518    0.7843      2232\n",
      "           2     0.8791    0.9279    0.9028      1983\n",
      "           3     0.7850    0.8772    0.8285      1132\n",
      "           4     0.9872    0.9893    0.9882     34909\n",
      "\n",
      "    accuracy                         0.9637     43525\n",
      "   macro avg     0.8792    0.8867    0.8819     43525\n",
      "weighted avg     0.9637    0.9637    0.9635     43525\n",
      "\n",
      "Epoch 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe4b7f439c848f3a218442b077f016a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [0/172046 (0%)]\tLoss: 0.007064\n",
      "Train Epoch: 22 [43008/172046 (25%)]\tLoss: 0.038653\n",
      "Train Epoch: 22 [86016/172046 (50%)]\tLoss: 0.042106\n",
      "Train Epoch: 22 [129024/172046 (75%)]\tLoss: 0.012066\n",
      "Train Epoch: 22 [75264/172046 (100%)]\tLoss: 0.030961\n",
      "\n",
      "Average loss on epoch 22: 0.05503848850699715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed95b59930f4475a75d0ac47abe0766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9235    0.8881    0.9055      3262\n",
      "           1     0.8212    0.7474    0.7826      2249\n",
      "           2     0.8791    0.9284    0.9031      1982\n",
      "           3     0.7858    0.8781    0.8294      1132\n",
      "           4     0.9870    0.9894    0.9882     34900\n",
      "\n",
      "    accuracy                         0.9636     43525\n",
      "   macro avg     0.8793    0.8863    0.8817     43525\n",
      "weighted avg     0.9635    0.9636    0.9634     43525\n",
      "\n",
      "Epoch 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b371f21ac343e9a9886720972e107d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [0/172046 (0%)]\tLoss: 0.014464\n",
      "Train Epoch: 23 [43008/172046 (25%)]\tLoss: 0.021138\n",
      "Train Epoch: 23 [86016/172046 (50%)]\tLoss: 0.026832\n",
      "Train Epoch: 23 [129024/172046 (75%)]\tLoss: 0.085343\n",
      "Train Epoch: 23 [75264/172046 (100%)]\tLoss: 0.070216\n",
      "\n",
      "Average loss on epoch 23: 0.05552467903463866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6004b801a6374bbba758084baa74f8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.8844    0.9064      3297\n",
      "           1     0.8178    0.7571    0.7863      2211\n",
      "           2     0.8758    0.9290    0.9016      1973\n",
      "           3     0.7826    0.8761    0.8267      1130\n",
      "           4     0.9873    0.9893    0.9883     34914\n",
      "\n",
      "    accuracy                         0.9639     43525\n",
      "   macro avg     0.8786    0.8872    0.8819     43525\n",
      "weighted avg     0.9640    0.9639    0.9637     43525\n",
      "\n",
      "Epoch 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31f83f5a0ee40bfbacda87b82092e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [0/172046 (0%)]\tLoss: 0.016915\n",
      "Train Epoch: 24 [43008/172046 (25%)]\tLoss: 0.035541\n",
      "Train Epoch: 24 [86016/172046 (50%)]\tLoss: 0.043978\n",
      "Train Epoch: 24 [129024/172046 (75%)]\tLoss: 0.031192\n",
      "Train Epoch: 24 [75264/172046 (100%)]\tLoss: 0.169692\n",
      "\n",
      "Average loss on epoch 24: 0.05534880992705139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93a5a12226f414c85e6f636bc02421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9248    0.8880    0.9060      3267\n",
      "           1     0.8202    0.7519    0.7846      2233\n",
      "           2     0.8758    0.9290    0.9016      1973\n",
      "           3     0.7858    0.8742    0.8276      1137\n",
      "           4     0.9873    0.9892    0.9882     34915\n",
      "\n",
      "    accuracy                         0.9637     43525\n",
      "   macro avg     0.8788    0.8865    0.8816     43525\n",
      "weighted avg     0.9637    0.9637    0.9635     43525\n",
      "\n",
      "CPU times: user 9min 22s, sys: 1min 12s, total: 10min 35s\n",
      "Wall time: 10min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_epochs = 5\n",
    "\n",
    "for epoch in range(len(logs['loss/train']), len(logs['loss/train']) + max_epochs):\n",
    "    \n",
    "    # Training\n",
    "    ffnet.train()\n",
    "    print('Epoch', epoch)\n",
    "    logs['loss/train'][epoch] = []\n",
    "    writer.add_scalar(\"Learning_rate\", optimizer_params['lr'], epoch)\n",
    "\n",
    "    for batch, (batch_X, batch_Y) in enumerate(tqdm(train_loader)):\n",
    "        # tranfer to GPU\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        l = backprop(batch_X, batch_Y, ffnet, optimizer, loss_fn)\n",
    "        logs['loss/train'][epoch].append(l)\n",
    "        \n",
    "        if batch % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch * len(batch_X), len(train_loader.dataset),\n",
    "                100. * batch / len(train_loader), l))\n",
    "    \n",
    "    logs['loss/train'][epoch] = np.mean(logs['loss/train'][epoch])\n",
    "    writer.add_scalar(\"Loss/train\", logs['loss/train'][epoch], epoch)\n",
    "    print(f'Average loss on epoch {epoch}: {logs[\"loss/train\"][epoch]}')\n",
    "    \n",
    "    # Validation\n",
    "    ffnet.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        gt = []\n",
    "        for batch, (batch_X, batch_Y) in enumerate(tqdm(dev_loader)):\n",
    "            # Transfer to GPU\n",
    "            batch_X = batch_X.to(device)\n",
    "            output = nn.Softmax(dim=1)(ffnet(batch_X))\n",
    "            preds.append(output.cpu())\n",
    "            gt.append(batch_Y)\n",
    "    \n",
    "        all_out = [np.argmax(l) for batch in preds for l in batch.numpy()]\n",
    "        all_gt  = [l for batch in gt for l in batch.numpy()]\n",
    "        \n",
    "        print(classification_report(all_out, all_gt, digits=4))\n",
    "        micro_F1 = metrics.f1_score(all_gt, all_out, average='micro')\n",
    "        macro_F1 = metrics.f1_score(all_gt, all_out, average='macro')\n",
    "        weighted_F1 = metrics.f1_score(all_gt, all_out, average='weighted')\n",
    "        writer.add_scalar(\"micro_F1/dev\", micro_F1, epoch)\n",
    "        writer.add_scalar(\"macro_F1/dev\", macro_F1, epoch)\n",
    "        writer.add_scalar(\"weighted_F1/dev\", weighted_F1, epoch)\n",
    "        logs['dev'][epoch] = (micro_F1, weighted_F1, macro_F1, (all_gt, all_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7e4c56f2ab4ebab28b8d00bcb568a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8918    0.8551    0.8731      2892\n",
      "           1     0.7371    0.6905    0.7130      2659\n",
      "           2     0.8073    0.8557    0.8308      1816\n",
      "           3     0.7346    0.7001    0.7170       957\n",
      "           4     0.9776    0.9847    0.9811     30783\n",
      "\n",
      "    accuracy                         0.9421     39107\n",
      "   macro avg     0.8297    0.8172    0.8230     39107\n",
      "weighted avg     0.9410    0.9421    0.9415     39107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ffnet.eval()\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    gt = []\n",
    "    for batch, (batch_X, batch_Y) in enumerate(tqdm(test_loader)):\n",
    "        # Transfer to GPU\n",
    "        batch_X = batch_X.to(device)\n",
    "        output = nn.Softmax(dim=1)(ffnet(batch_X))\n",
    "        preds.append(output.cpu())\n",
    "        gt.append(batch_Y)\n",
    "\n",
    "    all_out = [np.argmax(l) for batch in preds for l in batch.numpy()]\n",
    "    all_gt  = [l for batch in gt for l in batch.numpy()]\n",
    "\n",
    "    print(classification_report(all_out, all_gt, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8330477919554045, 0.8547009930379798, 0.6680419619738478)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs1['dev'][39][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
