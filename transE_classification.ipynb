{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7e0418bbd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'transe300/embeddings/transe/'\n",
    "embeddings_df = pd.read_csv(dataset_path+'ent_embedding.tsv', sep='\\t', header=None)\n",
    "embeddings_labels = pd.read_csv(dataset_path+'ent_labels.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19046"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = pickle.load(open('vocabulary_all.pickle', 'rb'))\n",
    "word2id = {w:i for i,w in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19046"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(vocabulary[k]) for k in vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.376816</td>\n",
       "      <td>-2.660249</td>\n",
       "      <td>-1.720779</td>\n",
       "      <td>-3.738140</td>\n",
       "      <td>-1.410253</td>\n",
       "      <td>-4.303190</td>\n",
       "      <td>-0.444410</td>\n",
       "      <td>2.566693</td>\n",
       "      <td>-2.692881</td>\n",
       "      <td>-3.623276</td>\n",
       "      <td>...</td>\n",
       "      <td>1.702528</td>\n",
       "      <td>-2.827910</td>\n",
       "      <td>-3.283765</td>\n",
       "      <td>-2.932739</td>\n",
       "      <td>4.396580</td>\n",
       "      <td>-3.065178</td>\n",
       "      <td>-1.436150</td>\n",
       "      <td>-1.800443</td>\n",
       "      <td>1.500156</td>\n",
       "      <td>-3.188193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329408</td>\n",
       "      <td>3.283797</td>\n",
       "      <td>1.413908</td>\n",
       "      <td>-1.478796</td>\n",
       "      <td>1.787328</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>3.308312</td>\n",
       "      <td>1.074971</td>\n",
       "      <td>1.750265</td>\n",
       "      <td>3.795927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.943173</td>\n",
       "      <td>1.075494</td>\n",
       "      <td>3.930749</td>\n",
       "      <td>4.084786</td>\n",
       "      <td>-0.168675</td>\n",
       "      <td>-4.480431</td>\n",
       "      <td>-4.133200</td>\n",
       "      <td>4.235694</td>\n",
       "      <td>1.882890</td>\n",
       "      <td>-3.120216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.126465</td>\n",
       "      <td>0.528410</td>\n",
       "      <td>2.327674</td>\n",
       "      <td>-4.407062</td>\n",
       "      <td>2.473155</td>\n",
       "      <td>-2.692419</td>\n",
       "      <td>-3.859272</td>\n",
       "      <td>4.164910</td>\n",
       "      <td>-4.836650</td>\n",
       "      <td>-6.731491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560506</td>\n",
       "      <td>-4.260564</td>\n",
       "      <td>4.665086</td>\n",
       "      <td>6.829501</td>\n",
       "      <td>3.161113</td>\n",
       "      <td>-5.295737</td>\n",
       "      <td>-4.141501</td>\n",
       "      <td>1.192512</td>\n",
       "      <td>4.569420</td>\n",
       "      <td>-10.280411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.994188</td>\n",
       "      <td>-5.458786</td>\n",
       "      <td>-4.283843</td>\n",
       "      <td>-4.673262</td>\n",
       "      <td>-0.887951</td>\n",
       "      <td>1.723410</td>\n",
       "      <td>0.915514</td>\n",
       "      <td>-2.708116</td>\n",
       "      <td>3.080909</td>\n",
       "      <td>-4.856210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334868</td>\n",
       "      <td>-5.392769</td>\n",
       "      <td>-0.364074</td>\n",
       "      <td>-2.457933</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>-2.109209</td>\n",
       "      <td>0.346354</td>\n",
       "      <td>-1.231177</td>\n",
       "      <td>4.252873</td>\n",
       "      <td>-8.651485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.736406</td>\n",
       "      <td>4.844031</td>\n",
       "      <td>-0.655391</td>\n",
       "      <td>-5.600396</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>0.586715</td>\n",
       "      <td>2.920149</td>\n",
       "      <td>4.049066</td>\n",
       "      <td>-7.120113</td>\n",
       "      <td>7.633911</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.595132</td>\n",
       "      <td>7.347126</td>\n",
       "      <td>-3.256641</td>\n",
       "      <td>7.024849</td>\n",
       "      <td>-0.754481</td>\n",
       "      <td>2.643580</td>\n",
       "      <td>-6.352776</td>\n",
       "      <td>4.000177</td>\n",
       "      <td>-0.699216</td>\n",
       "      <td>1.370345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.376816 -2.660249 -1.720779 -3.738140 -1.410253 -4.303190 -0.444410   \n",
       "1  0.329408  3.283797  1.413908 -1.478796  1.787328  0.017077  3.308312   \n",
       "2  2.126465  0.528410  2.327674 -4.407062  2.473155 -2.692419 -3.859272   \n",
       "3  2.994188 -5.458786 -4.283843 -4.673262 -0.887951  1.723410  0.915514   \n",
       "4  3.736406  4.844031 -0.655391 -5.600396 -0.018026  0.586715  2.920149   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  2.566693 -2.692881 -3.623276  ...  1.702528 -2.827910 -3.283765 -2.932739   \n",
       "1  1.074971  1.750265  3.795927  ... -0.943173  1.075494  3.930749  4.084786   \n",
       "2  4.164910 -4.836650 -6.731491  ...  0.560506 -4.260564  4.665086  6.829501   \n",
       "3 -2.708116  3.080909 -4.856210  ...  0.334868 -5.392769 -0.364074 -2.457933   \n",
       "4  4.049066 -7.120113  7.633911  ... -2.595132  7.347126 -3.256641  7.024849   \n",
       "\n",
       "        294       295       296       297       298        299  \n",
       "0  4.396580 -3.065178 -1.436150 -1.800443  1.500156  -3.188193  \n",
       "1 -0.168675 -4.480431 -4.133200  4.235694  1.882890  -3.120216  \n",
       "2  3.161113 -5.295737 -4.141501  1.192512  4.569420 -10.280411  \n",
       "3  0.049093 -2.109209  0.346354 -1.231177  4.252873  -8.651485  \n",
       "4 -0.754481  2.643580 -6.352776  4.000177 -0.699216   1.370345  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<$>', '<ACRONYM>', '<ADJP>', '<ADVP>', '<ALL_CAPS>'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_labels.head().values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_embeddings = scaler.fit_transform(embeddings_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.107777</td>\n",
       "      <td>-0.726387</td>\n",
       "      <td>-0.463679</td>\n",
       "      <td>-1.007598</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>-1.221623</td>\n",
       "      <td>-0.215409</td>\n",
       "      <td>0.655358</td>\n",
       "      <td>-0.798581</td>\n",
       "      <td>-0.982443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586880</td>\n",
       "      <td>-0.756580</td>\n",
       "      <td>-0.894967</td>\n",
       "      <td>-0.835887</td>\n",
       "      <td>1.141270</td>\n",
       "      <td>-0.876541</td>\n",
       "      <td>-0.340067</td>\n",
       "      <td>-0.520436</td>\n",
       "      <td>0.412613</td>\n",
       "      <td>-0.838526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082893</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.393266</td>\n",
       "      <td>-0.388164</td>\n",
       "      <td>0.498001</td>\n",
       "      <td>-0.038548</td>\n",
       "      <td>0.810153</td>\n",
       "      <td>0.246311</td>\n",
       "      <td>0.409314</td>\n",
       "      <td>1.057024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132752</td>\n",
       "      <td>0.310807</td>\n",
       "      <td>1.090045</td>\n",
       "      <td>1.081382</td>\n",
       "      <td>-0.108296</td>\n",
       "      <td>-1.264005</td>\n",
       "      <td>-1.083799</td>\n",
       "      <td>1.148822</td>\n",
       "      <td>0.512016</td>\n",
       "      <td>-0.819825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568071</td>\n",
       "      <td>0.144069</td>\n",
       "      <td>0.643066</td>\n",
       "      <td>-1.190993</td>\n",
       "      <td>0.686239</td>\n",
       "      <td>-0.780525</td>\n",
       "      <td>-1.148639</td>\n",
       "      <td>1.093608</td>\n",
       "      <td>-1.381377</td>\n",
       "      <td>-1.836861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276250</td>\n",
       "      <td>-1.148339</td>\n",
       "      <td>1.292091</td>\n",
       "      <td>1.831269</td>\n",
       "      <td>0.803108</td>\n",
       "      <td>-1.487217</td>\n",
       "      <td>-1.086089</td>\n",
       "      <td>0.307248</td>\n",
       "      <td>1.209762</td>\n",
       "      <td>-2.789654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802343</td>\n",
       "      <td>-1.490347</td>\n",
       "      <td>-1.164355</td>\n",
       "      <td>-1.263976</td>\n",
       "      <td>-0.236279</td>\n",
       "      <td>0.428719</td>\n",
       "      <td>0.156237</td>\n",
       "      <td>-0.791055</td>\n",
       "      <td>0.771058</td>\n",
       "      <td>-1.321364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214876</td>\n",
       "      <td>-1.457941</td>\n",
       "      <td>-0.091639</td>\n",
       "      <td>-0.706164</td>\n",
       "      <td>-0.048690</td>\n",
       "      <td>-0.614818</td>\n",
       "      <td>0.151472</td>\n",
       "      <td>-0.363009</td>\n",
       "      <td>1.127548</td>\n",
       "      <td>-2.341522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.002730</td>\n",
       "      <td>1.322171</td>\n",
       "      <td>-0.172428</td>\n",
       "      <td>-1.518163</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.117443</td>\n",
       "      <td>0.704074</td>\n",
       "      <td>1.061842</td>\n",
       "      <td>-2.002150</td>\n",
       "      <td>2.112049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.582085</td>\n",
       "      <td>2.025787</td>\n",
       "      <td>-0.887504</td>\n",
       "      <td>1.884641</td>\n",
       "      <td>-0.268638</td>\n",
       "      <td>0.686389</td>\n",
       "      <td>-1.695864</td>\n",
       "      <td>1.083692</td>\n",
       "      <td>-0.158608</td>\n",
       "      <td>0.415566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.107777 -0.726387 -0.463679 -1.007598 -0.379634 -1.221623 -0.215409   \n",
       "1  0.082893  0.896250  0.393266 -0.388164  0.498001 -0.038548  0.810153   \n",
       "2  0.568071  0.144069  0.643066 -1.190993  0.686239 -0.780525 -1.148639   \n",
       "3  0.802343 -1.490347 -1.164355 -1.263976 -0.236279  0.428719  0.156237   \n",
       "4  1.002730  1.322171 -0.172428 -1.518163  0.002488  0.117443  0.704074   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  0.655358 -0.798581 -0.982443  ...  0.586880 -0.756580 -0.894967 -0.835887   \n",
       "1  0.246311  0.409314  1.057024  ... -0.132752  0.310807  1.090045  1.081382   \n",
       "2  1.093608 -1.381377 -1.836861  ...  0.276250 -1.148339  1.292091  1.831269   \n",
       "3 -0.791055  0.771058 -1.321364  ...  0.214876 -1.457941 -0.091639 -0.706164   \n",
       "4  1.061842 -2.002150  2.112049  ... -0.582085  2.025787 -0.887504  1.884641   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  1.141270 -0.876541 -0.340067 -0.520436  0.412613 -0.838526  \n",
       "1 -0.108296 -1.264005 -1.083799  1.148822  0.512016 -0.819825  \n",
       "2  0.803108 -1.487217 -1.086089  0.307248  1.209762 -2.789654  \n",
       "3 -0.048690 -0.614818  0.151472 -0.363009  1.127548 -2.341522  \n",
       "4 -0.268638  0.686389 -1.695864  1.083692 -0.158608  0.415566  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(normalized_embeddings).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6319f5e6bdd045a2b8826ba82031074d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = {}\n",
    "for i, vec in tqdm(enumerate(normalized_embeddings)):\n",
    "    token = embeddings_labels.values[i,0]\n",
    "    token_embeddings[token] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.07776996e-01, -7.26387380e-01, -4.63678589e-01, -1.00759757e+00,\n",
       "       -3.79634409e-01, -1.22162339e+00, -2.15409040e-01,  6.55358411e-01,\n",
       "       -7.98580864e-01, -9.82442887e-01, -5.35165124e-01,  1.39167390e-01,\n",
       "        4.99560891e-01,  1.35160254e-01, -8.72019472e-01,  1.61086451e-01,\n",
       "       -5.31787610e-01,  8.58735757e-01, -2.91400316e-01,  1.03111277e+00,\n",
       "       -9.60259295e-01, -3.62934227e-02,  3.08977416e-01, -6.90099667e-01,\n",
       "       -6.14423925e-01,  4.19666328e-01,  1.01956651e+00,  7.68356343e-01,\n",
       "        8.77950774e-01, -6.65465975e-01, -1.94618332e-01, -2.90986331e-01,\n",
       "        9.23103828e-01, -7.60354060e-01,  7.93220691e-01,  2.33960834e-01,\n",
       "       -6.22054066e-01,  8.38496785e-01,  7.24863198e-02,  5.19803522e-01,\n",
       "       -7.06852134e-01, -8.34160306e-01, -4.01838011e-01,  2.19816135e-01,\n",
       "       -1.05073685e+00, -6.56431525e-01, -7.82371669e-01, -3.29460202e-02,\n",
       "        2.15551453e-01, -1.11545241e+00, -7.20596359e-01, -1.99804405e-01,\n",
       "        5.88893671e-01, -6.20364447e-01, -1.00456981e+00, -8.01362824e-01,\n",
       "       -7.50383002e-01, -9.67700866e-01, -7.29970977e-01,  4.80987542e-01,\n",
       "       -9.27340324e-01, -2.81492794e-01, -7.28753667e-01, -9.46814231e-01,\n",
       "       -6.08117281e-01,  8.27722410e-01,  6.44247358e-02,  3.12057161e-01,\n",
       "       -6.25850291e-01, -7.35271530e-01, -1.11488845e-01, -7.64875817e-01,\n",
       "        5.62647187e-01, -5.22976670e-01, -8.15332914e-01,  5.60395780e-01,\n",
       "       -8.33612613e-01, -2.15677590e-01,  6.93554549e-01,  8.27024849e-01,\n",
       "        3.69849281e-01, -7.36313633e-01,  6.18634290e-01, -8.38939575e-01,\n",
       "        1.52505536e-01, -5.74177250e-01,  9.29167796e-01,  4.80313711e-01,\n",
       "        8.19635134e-01, -7.09545849e-01, -6.95055191e-01, -3.02155668e-01,\n",
       "        8.63951024e-01, -4.25272644e-01,  7.43833728e-01, -5.98557166e-01,\n",
       "       -7.01841919e-01,  8.05638130e-01, -7.02570126e-01,  4.29687590e-01,\n",
       "       -7.91158778e-01, -7.16625843e-01,  1.03624904e+00,  3.17168593e-01,\n",
       "        1.10021292e-03,  5.88372372e-01, -1.30430566e+00,  6.28591490e-01,\n",
       "        1.62185615e-01,  5.23617176e-01, -3.94127503e-01,  5.49816054e-01,\n",
       "       -2.29043349e-01, -1.19854893e-01,  3.61250383e-01, -6.98828868e-01,\n",
       "        5.89832110e-01, -3.12601225e-01,  8.52032340e-01, -2.74010394e-02,\n",
       "       -5.83782341e-01,  1.01333699e+00,  5.02439738e-01, -9.29225595e-01,\n",
       "        1.14337683e+00, -8.18247205e-01, -7.01644411e-01, -7.80983425e-01,\n",
       "       -7.53955189e-01,  7.94075860e-01, -1.00927768e+00, -8.04451993e-01,\n",
       "       -1.02455806e+00, -5.55572277e-01, -3.36374035e-01,  1.26135766e-01,\n",
       "       -7.07926936e-01,  6.94969562e-01,  3.48145716e-01, -1.17032171e+00,\n",
       "        8.86113820e-01,  9.87004678e-01, -7.99590796e-01,  7.46606840e-01,\n",
       "       -3.51990850e-01,  6.20870863e-02, -7.35687795e-01, -2.83694363e-01,\n",
       "       -6.85838431e-01, -5.96638404e-01,  9.64413135e-01,  1.47402911e-01,\n",
       "        9.42160457e-01,  6.95216952e-01, -7.23073868e-01, -3.92952124e-01,\n",
       "        9.54822425e-01, -8.77794535e-01, -3.67257365e-01, -7.64967107e-01,\n",
       "        6.96812205e-01,  2.18527741e-01,  7.93682637e-01, -2.52843144e-01,\n",
       "        4.98205447e-01,  5.96834379e-01, -9.27585664e-01, -8.06349290e-02,\n",
       "        4.77951379e-02, -6.16043135e-01,  5.75897283e-01,  5.90400303e-01,\n",
       "        7.42184251e-01, -2.86160228e-01, -7.01271206e-01,  8.52703462e-01,\n",
       "       -8.34425849e-01,  6.60915734e-01, -5.24393429e-01,  9.88552477e-01,\n",
       "        3.85890385e-01,  4.00695262e-01,  8.29929136e-01,  7.73445484e-01,\n",
       "        1.06500097e+00, -9.60546703e-01, -1.92937676e-02,  9.82631565e-01,\n",
       "        1.09531059e+00, -1.98859550e-02,  2.09211466e-01,  7.41048596e-01,\n",
       "        6.82307715e-01,  6.57097021e-01, -8.42396096e-01,  4.77844866e-01,\n",
       "       -1.58078506e-01,  7.58744090e-01,  3.64145786e-01,  3.87775110e-01,\n",
       "       -1.83854185e-01,  8.74951812e-01,  7.16854404e-01, -7.71791287e-01,\n",
       "       -8.23697285e-01,  6.54287826e-01,  6.06201219e-01,  8.42244875e-01,\n",
       "        7.15921638e-01,  8.91413176e-01, -2.04220593e-01,  6.63076872e-01,\n",
       "       -5.04343940e-01,  1.00647490e+00, -9.41095343e-01, -2.58708547e-01,\n",
       "       -7.27481330e-01,  4.64208425e-01,  5.55417331e-01,  7.39483482e-01,\n",
       "       -8.30859007e-01, -3.69613655e-01, -3.26963646e-02, -3.76023545e-01,\n",
       "       -2.18051847e-01,  7.84136163e-01,  9.24781157e-01, -4.40406219e-01,\n",
       "        7.32859456e-01,  6.19788211e-01, -8.55501128e-01, -8.21203695e-01,\n",
       "       -7.23688456e-01, -1.30308395e+00, -6.50133185e-01, -5.66538090e-01,\n",
       "        7.34180117e-01, -5.95431251e-01,  6.44588583e-01, -2.95340499e-01,\n",
       "        7.80937282e-01,  8.30561591e-01, -1.90776737e-01,  6.76027925e-01,\n",
       "        9.32731481e-01,  1.07356486e+00,  9.82122631e-01,  8.02614321e-01,\n",
       "        6.94472993e-01,  5.53742811e-01,  7.74486002e-01, -8.99849297e-01,\n",
       "       -7.39375977e-01,  7.67600146e-01, -6.40467774e-01,  3.24559784e-01,\n",
       "        2.20854256e-01,  6.24828629e-01,  9.27330784e-01, -1.37221757e-01,\n",
       "        6.46941582e-01, -7.94462641e-01,  7.14310533e-01, -6.28863044e-01,\n",
       "       -6.31557738e-01, -6.27450712e-01,  8.53145427e-01, -8.10289814e-01,\n",
       "        3.65012611e-01, -7.39838569e-01, -5.15359441e-01, -1.42168587e-01,\n",
       "        7.80113913e-01,  5.89986145e-01, -6.56082948e-01,  1.11176121e+00,\n",
       "        7.71465101e-01, -7.17449525e-02,  9.95973449e-01,  2.07213031e-01,\n",
       "        8.82435752e-01,  1.06278377e+00,  6.99057895e-01, -5.43453704e-01,\n",
       "        7.54317064e-01, -9.18809582e-01,  7.90167685e-01, -3.32878462e-01,\n",
       "       -3.86014769e-02, -3.78011885e-01,  5.86880040e-01, -7.56579652e-01,\n",
       "       -8.94966702e-01, -8.35886511e-01,  1.14127013e+00, -8.76540505e-01,\n",
       "       -3.40067221e-01, -5.20436321e-01,  4.12612680e-01, -8.38525543e-01])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings['<$>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open('conll_graph_all.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, dataset, dataset_split, nodes_embeddings, window_size = 2):\n",
    "        'Initialization'\n",
    "        X, Y, RAW = [], [], []\n",
    "        for doc in tqdm(dataset[dataset_split]):\n",
    "            word = doc['word'][0]\n",
    "            chunk = doc['chunk'][0]\n",
    "            pos = doc['pos'][0]\n",
    "            extras = doc['extra']\n",
    "            classes = doc['classes']\n",
    "            left_context = [w for w in doc['left_context'] if w in nodes_embeddings][-3:]\n",
    "            right_context = [w for w in doc['right_context'] if w in nodes_embeddings][:3]\n",
    "            \n",
    "            extra = [chunk, pos]\n",
    "            extra.extend(extras)\n",
    "            extra.extend(classes)\n",
    "            extra = [t.replace(' ', '_') if t.startswith('<') else t for t in extra]\n",
    "            \n",
    "            zeros = np.zeros(nodes_embeddings[token].shape)\n",
    "            \n",
    "            graph_rep = np.concatenate([nodes_embeddings[token],\n",
    "                                        zeros if len(left_context) == 0 else np.mean([nodes_embeddings[w] for w in left_context], axis=0),\n",
    "                                        zeros if len(right_context) == 0 else np.mean([nodes_embeddings[w] for w in right_context], axis=0),\n",
    "                                        np.mean([nodes_embeddings[w] for w in extra], axis=0),\n",
    "                                       ])\n",
    "\n",
    "            X.append(graph_rep)\n",
    "            Y.append(doc['label'])\n",
    "            RAW.append((token, left_context, right_context, extra))\n",
    "                \n",
    "        \n",
    "        self.X = np.array(X)\n",
    "        self.labels = sorted(set(Y))\n",
    "        self.y2index = {l: i for i, l in enumerate(self.labels)}\n",
    "        self.Y = np.array([self.y2index[y] for y in Y])\n",
    "        self.RAW = RAW\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "    \n",
    "    def get_raw_item(self, index):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.RAW[index]\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def get_Y(self):\n",
    "        return self.Y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        x = self.X[index] #.to('cuda') # [:voc_size]\n",
    "        y = self.Y[index]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c33a8b712a84927bc077ac62463f5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=178610.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e8192cb4bf48afa83074edc56166e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=44900.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111d03a3545e4b94b462536994d7ddad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40760.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size  = 64\n",
    "num_workers = 4\n",
    "\n",
    "train_set = Dataset(dataset, 'train', token_embeddings)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True) # , sampler=sampler) #\n",
    "\n",
    "dev_set = Dataset(dataset, 'validation', token_embeddings)\n",
    "dev_loader = DataLoader(dev_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "test_set = Dataset(dataset, 'test', token_embeddings)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': 0, 'MISC': 1, 'O': 2, 'ORG': 3, 'PER': 4}\n"
     ]
    }
   ],
   "source": [
    "labels = pickle.load(open('labels.pickle', 'rb'))\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5529681467181468,\n",
       " 1.0,\n",
       " 0.03168753586713775,\n",
       " 0.4590344551282051,\n",
       " 0.4119920891765552]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_set.get_labels()\n",
    "label_counter   = Counter([labels[y] for y in train_set.get_Y()])\n",
    "labels_freqs    = [label_counter[label] / sum(label_counter.values()) for label in labels]\n",
    "labels_weights  = [min(label_counter.values()) / label_counter[label] for label in labels]\n",
    "labels_weights2 = [np.sqrt(min(label_counter.values())) / np.sqrt(label_counter[label]) for label in labels]\n",
    "labels_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2791\n",
      "torch.Size([64, 1200])\n",
      "torch.Size([64])\n",
      "tensor(27.0221, dtype=torch.float64)\n",
      "Class distribution in this batch: Counter({2: 52, 0: 6, 3: 3, 4: 3})\n",
      "time: 0.54s\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(len(train_loader))\n",
    "for batch_X, batch_Y in train_loader:\n",
    "    print(batch_X.shape)\n",
    "    print(batch_Y.shape)\n",
    "    print(sum(batch_X[0]))\n",
    "    print('Class distribution in this batch:', Counter(batch_Y.numpy()))\n",
    "    break\n",
    "print(f'time: {time.time() - t:.3}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(batch_X, batch_Y, model, optimizer, loss_fn):\n",
    "    Y_hat = model(batch_X)\n",
    "    loss = loss_fn(Y_hat, batch_Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=input_dim, hidden_dim=256, output_dim=5, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fch = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # self.fch2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # extra layers layers\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc2(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = {'loss/train': {}, 'dev': {}}\n",
    "writer = SummaryWriter(comment='xp8-transe300-wei2-lr1e3-mom0.95-wd5e4-hd256-dr0.2-bs64-normalized', log_dir=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnet = FeedForwardNetwork(dropout_rate=0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7436, 1.0000, 0.1780, 0.6775, 0.6419], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "label_counter   = Counter([y.item() for y in train_set.Y])\n",
    "labels_freqs    = [label_counter[label] / sum(label_counter.values()) for label in range(len(labels))]\n",
    "labels_weights1 = [min(label_counter.values()) / label_counter[label] for label in range(len(labels))]\n",
    "labels_weights2 = [np.sqrt(min(label_counter.values())) / np.sqrt(label_counter[label]) for label in range(len(labels))]\n",
    "\n",
    "weights = torch.Tensor(labels_weights2).to(device)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_params = {'lr': 1e-3, \n",
    "                    'momentum': 0.95, \n",
    "                    'weight_decay': 5e-4,\n",
    "                   }\n",
    "\n",
    "log_interval = int(len(train_loader) / 5)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.SGD(ffnet.parameters(), **optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca5aba2553648d7948add5ae87b386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2791.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [0/178610 (0%)]\tLoss: 0.133672\n",
      "Train Epoch: 32 [35712/178610 (20%)]\tLoss: 0.123978\n",
      "Train Epoch: 32 [71424/178610 (40%)]\tLoss: 0.119029\n",
      "Train Epoch: 32 [107136/178610 (60%)]\tLoss: 0.209933\n",
      "Train Epoch: 32 [142848/178610 (80%)]\tLoss: 0.357546\n",
      "Train Epoch: 32 [139500/178610 (100%)]\tLoss: 0.138936\n",
      "\n",
      "Average loss on epoch 32: 0.1444724118093443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991973d62e47428b90572df3d949fce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=702.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7818    0.8040    0.7927      2036\n",
      "           1     0.7009    0.6384    0.6682      1391\n",
      "           2     0.9745    0.9858    0.9801     35921\n",
      "           3     0.6609    0.6577    0.6593      2074\n",
      "           4     0.8872    0.8002    0.8414      3478\n",
      "\n",
      "    accuracy                         0.9372     44900\n",
      "   macro avg     0.8010    0.7772    0.7883     44900\n",
      "weighted avg     0.9360    0.9372    0.9364     44900\n",
      "\n",
      "CPU times: user 2min 34s, sys: 2.88 s, total: 2min 37s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_epochs = 1\n",
    "\n",
    "for epoch in range(len(logs['loss/train']), len(logs['loss/train']) + max_epochs):\n",
    "    \n",
    "    # Training\n",
    "    ffnet.train()\n",
    "    print('Epoch', epoch)\n",
    "    logs['loss/train'][epoch] = []\n",
    "    writer.add_scalar(\"Learning_rate\", optimizer_params['lr'], epoch)\n",
    "\n",
    "    for batch, (batch_X, batch_Y) in enumerate(tqdm(train_loader)):\n",
    "        # tranfer to GPU\n",
    "        batch_X, batch_Y = batch_X.float().to(device), batch_Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        l = backprop(batch_X, batch_Y, ffnet, optimizer, loss_fn)\n",
    "        logs['loss/train'][epoch].append(l)\n",
    "        \n",
    "        if batch % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch * len(batch_X), len(train_loader.dataset),\n",
    "                100. * batch / len(train_loader), l))\n",
    "    \n",
    "    logs['loss/train'][epoch] = np.mean(logs['loss/train'][epoch])\n",
    "    writer.add_scalar(\"Loss/train\", logs['loss/train'][epoch], epoch)\n",
    "    print(f'Average loss on epoch {epoch}: {logs[\"loss/train\"][epoch]}')\n",
    "    \n",
    "    # Validation\n",
    "    ffnet.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        gt = []\n",
    "        for batch, (batch_X, batch_Y) in enumerate(tqdm(dev_loader)):\n",
    "            # Transfer to GPU\n",
    "            batch_X = batch_X.float().to(device)\n",
    "            output = nn.Softmax(dim=1)(ffnet(batch_X))\n",
    "            preds.append(output.cpu())\n",
    "            gt.append(batch_Y)\n",
    "\n",
    "        all_out = [np.argmax(l) for batch in preds for l in batch.numpy()]\n",
    "        all_gt  = [l for batch in gt for l in batch.numpy()]\n",
    "\n",
    "        print(classification_report(all_out, all_gt, digits=4))\n",
    "\n",
    "        micro_F1 = metrics.f1_score(all_gt, all_out, average='micro')\n",
    "        macro_F1 = metrics.f1_score(all_gt, all_out, average='macro')\n",
    "        weighted_F1 = metrics.f1_score(all_gt, all_out, average='weighted')\n",
    "        writer.add_scalar(\"micro_F1/dev\", micro_F1, epoch)\n",
    "        writer.add_scalar(\"macro_F1/dev\", macro_F1, epoch)\n",
    "        writer.add_scalar(\"weighted_F1/dev\", weighted_F1, epoch)\n",
    "        logs['dev'][epoch] = (micro_F1, weighted_F1, macro_F1, (all_gt, all_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6065f67b28084e1eacf45fa11fdf3727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=637.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7532    0.7254    0.7390      1999\n",
      "           1     0.6427    0.5203    0.5750      1134\n",
      "           2     0.9660    0.9847    0.9753     32029\n",
      "           3     0.6318    0.6315    0.6316      2494\n",
      "           4     0.8532    0.7622    0.8052      3104\n",
      "\n",
      "    accuracy                         0.9205     40760\n",
      "   macro avg     0.7694    0.7248    0.7452     40760\n",
      "weighted avg     0.9175    0.9205    0.9186     40760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ffnet.eval()\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    gt = []\n",
    "    for batch, (batch_X, batch_Y) in enumerate(tqdm(test_loader)):\n",
    "        # Transfer to GPU\n",
    "        batch_X = batch_X.float().to(device)\n",
    "        output = nn.Softmax(dim=1)(ffnet(batch_X))\n",
    "        preds.append(output.cpu())\n",
    "        gt.append(batch_Y)\n",
    "\n",
    "    all_out = [np.argmax(l) for batch in preds for l in batch.numpy()]\n",
    "    all_gt  = [l for batch in gt for l in batch.numpy()]\n",
    "\n",
    "    print(classification_report(all_out, all_gt, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIM = 50\n",
      "Without Normalization\n",
      "Eval   macro avg     0.7658    0.7460    0.7536     44900\n",
      "Test   macro avg     0.7360    0.6755    0.7005     40760\n",
      "\n",
      "Normalized \n",
      "Eval   macro         0.7703    0.7335    0.7506     44900\n",
      "Test   macro avg     0.7282    0.6775    0.7001     40760\n",
      "\n",
      "\n",
      "DIM = 300\n",
      "Eval   macro avg     0.8010    0.7772    0.7883     44900\n",
      "Test   macro avg     0.7694    0.7248    0.7452     40760\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print('''\n",
    "DIM = 50\n",
    "Without Normalization\n",
    "Eval   macro avg     0.7658    0.7460    0.7536     44900\n",
    "Test   macro avg     0.7360    0.6755    0.7005     40760\n",
    "\n",
    "Normalized \n",
    "Eval   macro         0.7703    0.7335    0.7506     44900\n",
    "Test   macro avg     0.7282    0.6775    0.7001     40760\n",
    "\n",
    "\n",
    "DIM = 300\n",
    "Eval   macro avg     0.8010    0.7772    0.7883     44900\n",
    "Test   macro avg     0.7694    0.7248    0.7452     40760\n",
    "\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
