{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.dgl.ai/en/latest/tutorials/models/1_gnn/4_rgcn.html#sphx-glr-tutorials-models-1-gnn-4-rgcn-py\n",
    "# https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn\n",
    "# https://github.com/dmlc/dgl/blob/master/python/dgl/contrib/data/knowledge_graph.py\n",
    "# https://docs.dgl.ai/en/latest/api/python/graph.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/opt/tmp/huggingface/datasets/conll2003/conll2003/1.0.0/26b70ce2b0f32cb35a27151dbfa2dbe88c82bcdaf8f29433bcdc612a9b314e83)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031e90ee919544508359b97618182a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='TRAIN', max=14041.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37442aad8d8e474a970cf98e86a60557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='VALIDATION', max=3250.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eef0d1068c7487181a0e3559d5927b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='TEST', max=3453.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_per_label = {}\n",
    "for split in['train', 'validation', 'test']:\n",
    "    for doc in tqdm(dataset[split], desc=split.upper()):\n",
    "        for word, label in zip(doc['words'], doc['ner']):\n",
    "            label = label.split('-')[-1]\n",
    "            if label not in words_per_label: \n",
    "                words_per_label[label] = set()\n",
    "            words_per_label[label].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ORG', 'O', 'MISC', 'PER', 'LOC'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_per_label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1343"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_per_label['MISC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl-cu101\n",
      "  Downloading dgl_cu101-0.6a201201-cp38-cp38-manylinux1_x86_64.whl (20.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.9 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl-cu101) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl-cu101) (1.18.4)\n",
      "Requirement already satisfied: networkx>=2.1 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl-cu101) (2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl-cu101) (2.23.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from networkx>=2.1->dgl-cu101) (4.4.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl-cu101) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl-cu101) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl-cu101) (1.25.9)\n",
      "Installing collected packages: dgl-cu101\n",
      "Successfully installed dgl-cu101-0.6a201201\n",
      "lrwxrwxrwx 1 root root 21 19 févr.  2020 /usr/local/cuda -> /usr/local/cuda-10.1/\n"
     ]
    }
   ],
   "source": [
    "! pip install --pre dgl-cu101\n",
    "! ls -al /usr/local/cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl\n",
      "  Downloading dgl-0.6a201201-cp38-cp38-manylinux1_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl) (2.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl) (1.18.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from dgl) (2.23.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from networkx>=2.1->dgl) (4.4.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from requests>=2.19.0->dgl) (1.25.9)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-0.6a201201\n"
     ]
    }
   ],
   "source": [
    "! pip install --pre dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from functools import partial\n",
    "\n",
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=None,\n",
    "                 activation=None, is_input_layer=False):\n",
    "        super(RGCNLayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.is_input_layer = is_input_layer\n",
    "\n",
    "        # sanity check\n",
    "        if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
    "            self.num_bases = self.num_rels\n",
    "\n",
    "        # weight bases in equation (3)\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.num_bases, self.in_feat,\n",
    "                                                self.out_feat))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # linear combination coefficients in equation (3)\n",
    "            self.w_comp = nn.Parameter(torch.Tensor(self.num_rels, self.num_bases))\n",
    "\n",
    "        # add bias\n",
    "        if self.bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
    "\n",
    "        # init trainable parameters\n",
    "        nn.init.xavier_uniform_(self.weight,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            nn.init.xavier_uniform_(self.w_comp,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "        if self.bias:\n",
    "            nn.init.xavier_uniform_(self.bias,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # generate all weights from bases (equation (3))\n",
    "            weight = self.weight.view(self.in_feat, self.num_bases, self.out_feat)\n",
    "            weight = torch.matmul(self.w_comp, weight).view(self.num_rels,\n",
    "                                                        self.in_feat, self.out_feat)\n",
    "        else:\n",
    "            weight = self.weight\n",
    "\n",
    "        if self.is_input_layer:\n",
    "            def message_func(edges):\n",
    "                # for input layer, matrix multiply can be converted to be\n",
    "                # an embedding lookup using source node id\n",
    "                embed = weight.view(-1, self.out_feat)\n",
    "                index = edges.data['rel_type'] * self.in_feat + edges.src['id']\n",
    "                return {'msg': embed[index] * edges.data['norm']}\n",
    "        else:\n",
    "            def message_func(edges):\n",
    "                w = weight[edges.data['rel_type']]\n",
    "                msg = torch.bmm(edges.src['h'].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data['norm']\n",
    "                return {'msg': msg}\n",
    "\n",
    "        def apply_func(nodes):\n",
    "            h = nodes.data['h']\n",
    "            if self.bias:\n",
    "                h = h + self.bias\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            return {'h': h}\n",
    "\n",
    "        g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim, out_dim, num_rels,\n",
    "                 num_bases=-1, num_hidden_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        # create rgcn layers\n",
    "        self.build_model()\n",
    "\n",
    "        # create initial features\n",
    "        self.features = self.create_features()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input to hidden\n",
    "        i2h = self.build_input_layer()\n",
    "        self.layers.append(i2h)\n",
    "        # hidden to hidden\n",
    "        for _ in range(self.num_hidden_layers):\n",
    "            h2h = self.build_hidden_layer()\n",
    "            self.layers.append(h2h)\n",
    "        # hidden to output\n",
    "        h2o = self.build_output_layer()\n",
    "        self.layers.append(h2o)\n",
    "\n",
    "    # initialize feature for each node\n",
    "    def create_features(self):\n",
    "        features = torch.arange(self.num_nodes)\n",
    "        return features\n",
    "\n",
    "    def build_input_layer(self):\n",
    "        return RGCNLayer(self.num_nodes, self.h_dim, self.num_rels, self.num_bases,\n",
    "                         activation=F.relu, is_input_layer=True)\n",
    "\n",
    "    def build_hidden_layer(self):\n",
    "        return RGCNLayer(self.h_dim, self.h_dim, self.num_rels, self.num_bases,\n",
    "                         activation=F.relu)\n",
    "\n",
    "    def build_output_layer(self):\n",
    "        return RGCNLayer(self.h_dim, self.out_dim, self.num_rels, self.num_bases,\n",
    "                         activation=partial(F.softmax, dim=1))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.features is not None:\n",
    "            g.ndata['id'] = self.features\n",
    "        for layer in self.layers:\n",
    "            layer(g)\n",
    "        return g.ndata.pop('h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/semantic/.dgl/aifb.tgz from https://data.dgl.ai/dataset/aifb.tgz...\n",
      "Extracting file to /home/semantic/.dgl/aifb\n",
      "Loading dataset aifb\n",
      "Graph loaded, frequencies counted.\n",
      "Number of nodes:  8285\n",
      "Number of relations:  91\n",
      "Number of edges:  66371\n",
      "4 classes: {'http://www.aifb.uni-karlsruhe.de/Forschungsgruppen/viewForschungsgruppeOWL/id1instance', 'http://www.aifb.uni-karlsruhe.de/Forschungsgruppen/viewForschungsgruppeOWL/id2instance', 'http://www.aifb.uni-karlsruhe.de/Forschungsgruppen/viewForschungsgruppeOWL/id3instance', 'http://www.aifb.uni-karlsruhe.de/Forschungsgruppen/viewForschungsgruppeOWL/id4instance'}\n",
      "Loading training set\n",
      "Loading test set\n",
      "Number of classes:  4\n",
      "removing nodes that are more than 3 hops away\n"
     ]
    }
   ],
   "source": [
    "from dgl.contrib.data import load_data\n",
    "data = load_data(dataset='aifb')\n",
    "num_nodes = data.num_nodes\n",
    "num_rels = data.num_rels\n",
    "num_classes = data.num_classes\n",
    "labels = data.labels\n",
    "train_idx = data.train_idx\n",
    "# split training and validation set\n",
    "val_idx = train_idx[:len(train_idx) // 5]\n",
    "train_idx = train_idx[len(train_idx) // 5:]\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(data.edge_type)\n",
    "edge_norm = torch.from_numpy(data.edge_norm).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8285\n",
      "91\n",
      "4\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "tensor([ 0,  2,  5,  ...,  0, 21,  0])\n",
      "tensor([[1.0000],\n",
      "        [0.0192],\n",
      "        [0.0217],\n",
      "        ...,\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "torch.Size([8285])\n"
     ]
    }
   ],
   "source": [
    "print(num_nodes)\n",
    "print(num_rels)\n",
    "print(num_classes)\n",
    "print(labels)\n",
    "print(edge_type)\n",
    "print(edge_norm)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 8182, 2: 60, 1: 28, 3: 15})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 27409,\n",
       "         0.01923077: 208,\n",
       "         0.02173913: 92,\n",
       "         0.25: 2840,\n",
       "         0.125: 1032,\n",
       "         0.5: 6494,\n",
       "         0.16666667: 1392,\n",
       "         0.07692308: 507,\n",
       "         0.33333334: 3786,\n",
       "         0.14285715: 1176,\n",
       "         0.1: 660,\n",
       "         0.025: 120,\n",
       "         0.041666668: 240,\n",
       "         0.2: 1615,\n",
       "         0.024390243: 205,\n",
       "         0.035714287: 84,\n",
       "         0.05882353: 204,\n",
       "         0.06666667: 240,\n",
       "         0.09090909: 737,\n",
       "         0.0056497175: 177,\n",
       "         0.014492754: 69,\n",
       "         0.083333336: 456,\n",
       "         0.11111111: 531,\n",
       "         0.020833334: 192,\n",
       "         0.021276595: 188,\n",
       "         0.01754386: 57,\n",
       "         0.020408163: 147,\n",
       "         0.017857144: 56,\n",
       "         0.045454547: 220,\n",
       "         0.014705882: 68,\n",
       "         0.014925373: 134,\n",
       "         0.071428575: 266,\n",
       "         0.00591716: 338,\n",
       "         0.0069444445: 144,\n",
       "         0.0037453184: 267,\n",
       "         0.04347826: 138,\n",
       "         0.037037037: 135,\n",
       "         0.015151516: 66,\n",
       "         0.013333334: 150,\n",
       "         0.030303031: 99,\n",
       "         0.006369427: 314,\n",
       "         0.013513514: 74,\n",
       "         0.013888889: 72,\n",
       "         0.022727273: 132,\n",
       "         0.0625: 240,\n",
       "         0.0011415525: 876,\n",
       "         0.023255814: 129,\n",
       "         0.03846154: 130,\n",
       "         0.03125: 128,\n",
       "         0.007518797: 133,\n",
       "         0.0078125: 128,\n",
       "         0.05263158: 266,\n",
       "         0.011494253: 261,\n",
       "         0.0070422534: 142,\n",
       "         0.0091743115: 109,\n",
       "         0.0009569378: 1045,\n",
       "         0.05: 260,\n",
       "         0.018181818: 220,\n",
       "         0.015873017: 63,\n",
       "         0.02: 100,\n",
       "         0.015384615: 260,\n",
       "         0.015625: 64,\n",
       "         0.03448276: 58,\n",
       "         0.032258064: 124,\n",
       "         0.055555556: 234,\n",
       "         0.04: 150,\n",
       "         0.006024096: 166,\n",
       "         0.029411765: 68,\n",
       "         0.006849315: 146,\n",
       "         0.033333335: 90,\n",
       "         0.04761905: 84,\n",
       "         0.008333334: 120,\n",
       "         0.008403362: 119,\n",
       "         0.02631579: 190,\n",
       "         0.027777778: 36,\n",
       "         0.010309278: 194,\n",
       "         0.014285714: 70,\n",
       "         0.0076923077: 130,\n",
       "         0.023809524: 42,\n",
       "         0.028571429: 70,\n",
       "         0.012820513: 78,\n",
       "         0.011904762: 84,\n",
       "         0.009090909: 110,\n",
       "         0.016393442: 61,\n",
       "         0.027027028: 111,\n",
       "         0.010526316: 190,\n",
       "         0.0008183306: 1222,\n",
       "         0.019607844: 51,\n",
       "         0.0062111802: 161,\n",
       "         0.018867925: 53,\n",
       "         0.016666668: 60,\n",
       "         0.005: 200,\n",
       "         0.0051020407: 196,\n",
       "         0.007194245: 139,\n",
       "         0.006060606: 165,\n",
       "         0.0065789474: 152,\n",
       "         0.025641026: 117,\n",
       "         0.01724138: 116,\n",
       "         0.011111111: 90,\n",
       "         0.0046948357: 213,\n",
       "         0.004878049: 205,\n",
       "         0.011235955: 89,\n",
       "         0.012987013: 77,\n",
       "         0.007751938: 129,\n",
       "         0.0121951215: 82,\n",
       "         0.004237288: 236,\n",
       "         0.005291005: 189,\n",
       "         0.0014556041: 687})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(edge_norm.numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SPARQLWrapper\n",
      "  Downloading SPARQLWrapper-1.8.5-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: rdflib>=4.0 in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from SPARQLWrapper) (5.0.0)\n",
      "Requirement already satisfied: isodate in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from rdflib>=4.0->SPARQLWrapper) (0.6.0)\n",
      "Requirement already satisfied: six in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from rdflib>=4.0->SPARQLWrapper) (1.14.0)\n",
      "Requirement already satisfied: pyparsing in /home/semantic/.conda/envs/ismail-transformers/lib/python3.8/site-packages (from rdflib>=4.0->SPARQLWrapper) (2.4.7)\n",
      "Installing collected packages: SPARQLWrapper\n",
      "Successfully installed SPARQLWrapper-1.8.5\n"
     ]
    }
   ],
   "source": [
    "! pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
